* Multinode MCP TLS

** Prepare environment

Nodes are created with the help of heat templates.

git clone git@github.com:Mirantis/mk-lab-heat-templates.git

source ~/openrc_mirantis_devcloud

source ~/m/nova/.tox/py27/bin/activate

TEMPLATE=virtual_mcp11_ovs
STACK=avolkov

openstack stack create --insecure --debug \
  --environment "env/${TEMPLATE}.env" \
  --template "template/${TEMPLATE}.hot" \
  --parameter cluster_zone=mcp-oscore \
  --parameter cluster_domain=$TEMPLATE.local \
  "$STACK"

For TLS purpose, stacklight (mcp_sl_monitor) nodes are not required,
so it were excluded from resources.

** Report

*** Enabling TLS for inter-service communication

#+TITLE: TLS for MCP
#+DATE: 2017-10-02
#+AUTHOR: Andrey Volkov
#+EMAIL: avolkov@mirantis.com
#+OPTIONS: ^:nil
#+OPTIONS: f:t

**** General idea description

Common SaltStack formulas for components in the multinode deployment
are general enough to support plain inter-service communication and
TLS one as well. All changes to support TLS are done in a reclass
model. For the testing purpose, an os-ha-ovs reclass model was used.

Despite on reclass model changes only there are some environment
modification should be mentioned:

- an additional Nginx server is installed per each controller node.
  Nginx terminates TLS session and makes a plain proxy request to
  an OpenStack service. To understand why that is required a previous request
  flow should be observed:
     1) request to VIP to one of the controllers;
     2) HAProxy makes roundroubin balancing between controllers;
     3) service gets a request from HAProxy.

  Making communication secure between controllers requires a TLS
  termination on services but e.g. Nova uses eventlet for
  serving request and TLS support in eventlet have some issues.
  Other services can be provided as WSGI-application only.
  To make things more or less standardized it was decided to
  add Nginx as a new component of deployment.

- OpenStack services listen on localhost and Nginx listen
  on controller IP.

- HAProxy mode is changed from HTTP to TCP to make TLS connection
  to Nginx transparently.

- (Optional) Requests to controllers are made via FQDN rather
  than IP to make it available to use a wildcard certificate.

***** Schema before and after

Before:

file:mcp_tls_before.jpg

After:

file:mcp_tls_after.jpg

**** Steps to reproduce

***** Preparation

Given: the initial environment is deployed from an os-ha-ovs reclass model.

To make initial testing on the cfg node:

- Load environment variables from ctl01:/root/keystonercv3.
- Make bootstrap procedure and create image, flavor and test network.
- Boot test VM from cirros image.

After the smoke testing is done the TLS deploy can be started.
In the TLS deployment, all connections from a client to services
are encrypted. Connections between services are encrypted as well.

***** Fetch reclass model with a new control_tls class

#+BEGIN_SRC sh :dir /ssh:m_cfg|sudo:m_cfg:
cd /srv/salt/reclass/classes/cluster/os-ha-ovs
wget https://gerrit.mcp.mirantis.net/changes/8998/revisions/260b3c74c7eda52d2a3ebfcc6fa65f965fb85724/patch?zip -O patch.zip
apt install unzip
unzip patch.zip
patch --strip=4 --dry-run < *.diff
patch --strip=4 --backup < *.diff
cat openstack/control_tls.yml
#+END_SRC

For convenience, all changes to Nginx, services, HAProxy are described
in one file controld_tls.yml but it can be organized a different way.

***** Update generated models

To have a new class be applied to the required nodes we need to
regenerate the node definitions.

#+BEGIN_SRC sh
salt-call state.apply reclass
salt '*' saltutil.refresh_pillar; salt '*' saltutil.sync_all
grep control_tls /srv/salt/reclass/nodes/_generated/*
#+END_SRC

***** Generate certificates

The following certificate generation procedure must be automated with SaltStack.

#+BEGIN_SRC sh
# cat gen-cert.sh
# mkdir -p /etc/ssl/cluster
# openssl genrsa -out /etc/ssl/cluster/$1.key 2048
# openssl req -new -key /etc/ssl/cluster/$1.key \
#         -subj "/C=US/ST=Denial/L=Springfield/O=Dis/CN=$2" \
#         -out /etc/ssl/cluster/$1.csr
# openssl x509 -req -days 365 -in /etc/ssl/cluster/$1.csr \
#                 -signkey /etc/ssl/cluster/$1.key \
#                 -out /etc/ssl/cluster/$1.crt
# cat /etc/ssl/cluster/$1.crt /etc/ssl/cluster/$1.key > /etc/ssl/cluster/$1.pem
bash gen-cert.sh cluster '*.vsaienko-deploy-heat-os-ha-ovs-121.bud-mk.local'
#+END_SRC

***** Push certificates

The following certificate distribution procedure must be automated with SaltStack.

#+BEGIN_SRC sh
salt -E '^(ctl|cmp).*' cmd.run 'mkdir -p /etc/ssl/cluster'
salt-cp -E '^(ctl|cmp).*' /etc/ssl/cluster/cluster* /etc/ssl/cluster/
salt -E '^(cfg|ctl|cmp).*' cmd.run 'cat /etc/ssl/cluster/cluster.crt >> /etc/ssl/certs/ca-certificates.crt'
#+END_SRC

***** Move services to the localhost

#+BEGIN_SRC sh
salt ctl* state.sls keystone
salt ctl* state.sls glance
salt ctl* state.sls neutron
salt ctl* state.sls nova
#+END_SRC

***** Start Nginx on controller ip

#+BEGIN_SRC sh
salt ctl* state.sls nginx
salt ctl* cmd.run 'mv /etc/nginx/sites-available/default /root/nginx_default_backup'
salt ctl* state.sls nginx
#+END_SRC

***** Check services up and running

#+BEGIN_SRC sh
salt ctl* cmd.run 'netstat -natp | grep -i listen | grep 5000'
salt ctl* cmd.run 'netstat -natp | grep -i listen | grep 35357'
salt ctl* cmd.run 'netstat -natp | grep -i listen | grep 9292'
salt ctl* cmd.run 'netstat -natp | grep -i listen | grep 9696'
salt ctl* cmd.run 'netstat -natp | grep -i listen | grep 8774'
salt ctl* cmd.run 'netstat -natp | grep -i listen | grep 8778'
#+END_SRC

***** Update HAProxy mode for particular ports

#+BEGIN_SRC sh
salt ctl* state.sls haproxy
#+END_SRC

Also HAProxy timeout could be increased at this point to give a room
for the TLS additional payload.

***** Update endpoints in service catalog

For the endpoint update localhost identity service is used.

#+BEGIN_SRC sh
export OS_IDENTITY_API_VERSION=3
export OS_AUTH_URL=http://127.0.0.1:35357/v3
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=admin
export OS_TENANT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=workshop
export OS_REGION_NAME=RegionOne
export OS_INTERFACE=internal
export OS_CACERT="/etc/ssl/cluster/cluster.pem"

export CTL_HOST="ctl.vsaienko-deploy-heat-os-ha-ovs-121.bud-mk.local"
openstack endpoint set $(openstack endpoint list --service identity --interface internal | grep identity | awk '{print $2}') --url https://$CTL_HOST:5000/v2.0
openstack endpoint set $(openstack endpoint list --service identity --interface admin | grep identity | awk '{print $2}') --url https://$CTL_HOST:35357/v2.0

openstack endpoint set $(openstack endpoint list --service glance --interface internal | grep glance | awk '{print $2}') --url https://$CTL_HOST:9292
openstack endpoint set $(openstack endpoint list --service glance --interface admin | grep glance | awk '{print $2}') --url https://$CTL_HOST:9292

openstack endpoint set $(openstack endpoint list --service neutron --interface internal | grep neutron | awk '{print $2}') --url https://$CTL_HOST:9696/
openstack endpoint set $(openstack endpoint list --service neutron --interface admin | grep neutron | awk '{print $2}') --url https://$CTL_HOST:9696/

openstack endpoint set $(openstack endpoint list --service nova --interface internal | grep nova | awk '{print $2}') --url https://$CTL_HOST:8774/v2.1/'$(project_id)s'
openstack endpoint set $(openstack endpoint list --service nova --interface admin | grep nova | awk '{print $2}') --url https://$CTL_HOST:8774/v2.1/'$(project_id)s'

openstack endpoint set $(openstack endpoint list --service placement --interface internal | grep placement | awk '{print $2}') --url https://$CTL_HOST:8778
openstack endpoint set $(openstack endpoint list --service placement --interface admin | grep placement | awk '{print $2}') --url https://$CTL_HOST:8778
#+END_SRC

***** Apply TLS configurations for compute nodes

#+BEGIN_SRC sh
salt cmp* state.sls nova
#+END_SRC

***** Make smoke testing for OpenStack functionality

#+BEGIN_SRC sh
export OS_IDENTITY_API_VERSION=3
export OS_AUTH_URL=https://ctl.vsaienko-deploy-heat-os-ha-ovs-121.bud-mk.local:35357/v3
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=admin
export OS_TENANT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=workshop
export OS_REGION_NAME=RegionOne
export OS_INTERFACE=internal
export OS_CACERT="/etc/ssl/cluster/cluster.pem"

openstack endpoint list
openstack image list
openstack network list
openstack server list
openstack server create --image cirros-0.3.5-x86_64-disk --flavor c1 vm1
#+END_SRC
** Comments


